{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNA_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdhCTiVvrp7F",
        "colab_type": "text"
      },
      "source": [
        "# A DNA-Based Archival Storage System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-isgHXMGrp7I",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, we will presents an architecture for a DNA-based archival storage system. It is structured as a key-value store, and leverages common biochemical techniques to provide random access. We also propose a new encoding scheme that offers controllable redundancy, trading off reliability for\n",
        "density."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X0FuVhdrp7K",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "A DNA storage system consists of a DNA synthesizer that encodes the data to be stored in DNA, a storage container with compartments that store pools of DNA that map to a volume, and a DNA sequencer that reads DNA sequences\n",
        "and converts them back into digital data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_lOWb5Erp7L",
        "colab_type": "text"
      },
      "source": [
        "## âœï¸ Contributors: Muhammad Dahamshi & Firas Ramadan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SDKZwKjrp7U",
        "colab_type": "text"
      },
      "source": [
        "### Importing Packages & utilities\n",
        "Importing python packages as well as declaring configuration parameters and auxiliary functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioymWuA_rp7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import hashlib \n",
        "from termcolor import colored\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlopen  # the lib that handles the url stuff\n",
        "from typing import List\n",
        "import math \n",
        "import textwrap\n",
        "import random\n",
        "import copy\n",
        "import progressbar\n",
        "from time import sleep\n",
        "## This line makes matplotlib plot the figures inside the notebook\n",
        "%matplotlib inline\n",
        "primer_len = 10\n",
        "high_address_len = 5\n",
        "low_address_len = 15\n",
        "pay_load_len = 80\n",
        "dna_library_size = 40\n",
        "\n",
        "#### https://convertio.co/bin-jpg/ in order to convert the binary file to jpg files\n",
        "\t\n",
        "\n",
        "# utilities\n",
        "\n",
        "upside_down_letters = {'A':'ê“¯','C':'â†ƒ','G':'â…','T':'ê“•'}\n",
        "letters_complement = {'A':'T','C':'G','G':'C','T':'A'}\n",
        "\n",
        "def substract_lists(A,B):\n",
        "   return [item for item in A if item not in B]\n",
        "\n",
        "def upside_down_complement(nucleotide):\n",
        "  #return upside_down_letters[letters_complement[nucleotide]]\n",
        "  return letters_complement[nucleotide]\n",
        "\n",
        "def rotate(l, n):\n",
        "    return l[n:] + l[:n]\n",
        "\n",
        "def ternary(n):\n",
        "    if n == 0:\n",
        "        return '0'\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, 3)\n",
        "        nums.append(str(r))\n",
        "    return ''.join(reversed(nums))\n",
        "\n",
        "def str_to_bin(string: str) -> str:\n",
        "    return ''.join(format(ord(n), 'b') for n in string)\n",
        "\n",
        "def byte_to_bin(byte) -> str:\n",
        "    return ''.join(format(ord(byte), 'b').zfill(8) ) if len(byte) > 0 else ''\n",
        "\n",
        "def sub_str_from_indices(string: str, indeces) -> str:\n",
        "    return ''.join(string[i] for i in indeces)\n",
        "\n",
        "def get_as_ternary(string: str) -> str:\n",
        "    return ternary(int(string))\n",
        "\n",
        "def print_aux(string: str, color):\n",
        "        print(colored('\\033[1m' + string, color), end='')\n",
        "def print_seq(seq: str, data_len=pay_load_len):   \n",
        "    n1 = 0\n",
        "    n2 = primer_len\n",
        "    n3 = n2 + 1\n",
        "    n4 = n3 + data_len\n",
        "    n5 = n4 + low_address_len + high_address_len;\n",
        "    n7 = primer_len + data_len + 1\n",
        "    print_aux(seq[n1:n2], 'red')\n",
        "    print_aux(seq[n2], 'blue')\n",
        "    print_aux(seq[n3:n4], 'magenta')\n",
        "    print_aux(seq[n4:n5], 'yellow')\n",
        "    print_aux(seq[n5], 'blue')\n",
        "    print_aux(seq[-n2:], 'red')\n",
        "    print('')\n",
        "\n",
        "def print_colored(sequences: list):  \n",
        "    for i in range(len(sequences) - 1):\n",
        "        seq = sequences[i][0]\n",
        "        complement = sequences[i][1]\n",
        "        print_seq(seq)\n",
        "        print_seq(complement)\n",
        "        print('')\n",
        "    i = len(sequences) - 1\n",
        "    seq = sequences[i][0]\n",
        "    complement = sequences[i][1]\n",
        "    data_len = (len(seq) - (2 * primer_len + 2 + low_address_len + high_address_len))\n",
        "    print_seq(seq,data_len)\n",
        "    print_seq(complement,data_len)\n",
        "\n",
        "def split_into_fragments(string,frag_len):\n",
        "    return textwrap.wrap(string, frag_len)\n",
        "\n",
        "def get_complement_seq(sequences):\n",
        "    return ''.join(list(map(upside_down_complement,sequences)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B4WvDI2rp7c",
        "colab_type": "text"
      },
      "source": [
        "## Huffman code, A method for the construction of minimum redundancy codes\n",
        "Huffman code that maps each binary byte to either 5 or 6 ternary digits. For\n",
        "example, the Huffman code maps the binary string 01100001 to the base-3 string 01112. The rotating nucleotide encoding maps this string to the DNA sequence CTCTG. The code maps more common ASCII characters to 5 digit strings, offering\n",
        "minor compression benefits for textual data, though the effect on overall storage density is insignificant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NDBWOGweu-o",
        "colab_type": "text"
      },
      "source": [
        "This part is resposible for the translation of the received binary code to huffman code using the translation table that is given below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj1ypqkIrp7d",
        "colab_type": "code",
        "outputId": "d0289021-f98c-4a43-d982-8d2c83d4e721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "huffman_path = 'https://raw.githubusercontent.com/Muhammad-Dahamshi/DNA-Storage-System/master/dna/data/huff3.dict.csv'\n",
        "## Loading the data, the using of converters is to keep leading zeros in a column when reading CSV,\n",
        "## thus,we have to prevent slicing of '00100' to '100' for example\n",
        "huffman_dict = pd.read_csv(huffman_path, converters={'code': lambda x: str(x)})\n",
        "\n",
        "## Show the first 100 rows\n",
        "huffman_dict.head(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>22201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>11220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>00211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>11201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>00102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>01112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>22010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>00012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    number   code\n",
              "0        0  22201\n",
              "1        1  00100\n",
              "2        2  11220\n",
              "3        3  00211\n",
              "4        4  20222\n",
              "..     ...    ...\n",
              "95      95  11201\n",
              "96      96  00102\n",
              "97      97  01112\n",
              "98      98  22010\n",
              "99      99  00012\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 547
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D7conUXfY7H",
        "colab_type": "text"
      },
      "source": [
        "This part includes functions that translate the binary code to ternary code and vice versa according to what we've called huffman dictionary ( translation table ) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSsRHZKyrp7l",
        "colab_type": "code",
        "outputId": "ce8860da-a73f-4d08-e368-c661eadd54dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "huffman_array = huffman_dict[['number', 'code']].values \t\n",
        "\n",
        "\n",
        "#print(huffman_array2[0:10])\n",
        "\n",
        "def huffman_code(x: int) -> str:\n",
        "        return str(huffman_array[x][1]) if (x >= 0 & x <= 255) else ''\n",
        "\n",
        "def get_huffman_index(string:str):\n",
        "\t\tfor j in range(len(huffman_array)):\n",
        "\t\t\t\tif huffman_array[j][1] == string:\n",
        "\t\t\t\t\treturn j \n",
        "\t\treturn -1\n",
        "\n",
        "def huffman_to_binary(huffman):\n",
        "\t\tstr_res = ''\n",
        "\t\tindex = 0\n",
        "\t\twhile len(huffman)>0:\n",
        "\t\t\tstr_to_convert = huffman[0:5]\n",
        "\t\t\tnum = get_huffman_index(str_to_convert)\n",
        "\t\t\tif(num == -1):\n",
        "\t\t\t\tstr_to_convert = huffman[0:6]\n",
        "\t\t\t\tnum = get_huffman_index(str_to_convert)\n",
        "\t\t\thuffman = huffman[len(str_to_convert):]\n",
        "\t\t\tstr_res = str_res + format(num, 'b').zfill(8)\n",
        "\t\treturn str_res\n",
        "\n",
        "\n",
        "print('Huffman code of number 5\\t = {}'.format(huffman_code(5)))\n",
        "print('Huffman code of number 250\\t = {}'.format(huffman_code(250)))\n",
        "print('Huffman code of number 97\\t = {}'.format(huffman_code(97)))\n",
        "print('Huffman code of number 94\\t = {}'.format(huffman_code(94)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Huffman code of number 5\t = 00222\n",
            "Huffman code of number 250\t = 22020\n",
            "Huffman code of number 97\t = 01112\n",
            "Huffman code of number 94\t = 222211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnA29u3Brp74",
        "colab_type": "text"
      },
      "source": [
        "## ðŸ“š Huffman To Nucleotides\n",
        "\n",
        "âœï¸ A rotating encoding to nucleotides avoids homopolymers (repetitions\n",
        "of the same nucleotide), which are error-prone\n",
        "\n",
        "# A comment about NumPy indexing\n",
        "![alt text](https://raw.githubusercontent.com/Muhammad-Dahamshi/DNA-Storage-System/master/pdf-images/rotating-encoding.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dirrB_YRfzDD",
        "colab_type": "text"
      },
      "source": [
        "As explained in the article, at the end what interests us is having nucleotides that could build a synthetic DNA while maintaining the lowest error rate possible, to do so we used the following function which translates the huffman codes to nucleotides while using a translation table that its goal is to prevent the repitition of the same nucleotides, a thing that increases the possiblities for errors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA1hJdj1rp75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "map_letters = ['A','C','G','T']\n",
        "def huffman_to_nucleotides(huff_num: str, previous='A') -> str:\n",
        "        nucleotides = ''\n",
        "        previous_letter = previous\n",
        "        base =['C','G', 'T', 'A'] \n",
        "        converter = [rotate(base,i) for i in range(3)]\n",
        "        for i in huff_num:\n",
        "            nucleotide = converter[int(i)][map_letters.index(previous_letter)]\n",
        "            nucleotides += nucleotide\n",
        "            previous_letter = nucleotide \n",
        "        return nucleotides\n",
        "\n",
        "def nucleotides_to_huffman (nucleotides):\n",
        "\t\thuffman = ''\n",
        "\t\tprevious_letter = 'A'\n",
        "\t\tbase = map_letters\n",
        "\t\tconverter = {'A': rotate(base,0)[1:] , 'C':  rotate(base,1)[1:]\n",
        "\t\t            ,'G': rotate(base,2)[1:], 'T':  rotate(base,3)[1:]}\n",
        "\t\tfor i in range(len(nucleotides)):\n",
        "\t\t\t\tcur = nucleotides[i]\n",
        "\t\t\t\thuffman += str(converter[previous_letter].index(cur))\n",
        "\t\t\t\tprevious_letter = nucleotides[i]\n",
        "\t\treturn huffman\n",
        "\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kkIdqgRtMNoz"
      },
      "source": [
        "# Data Keys to nucleotides Primers\n",
        "The next part is responsible for applying the known hash function SHA-256 \n",
        "on the file/data keys that we are interested in reading/writing from/to the right DNA pool. Then it translates the hash function's outcome to nucleotides using the function and the translations we declared before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7URDgo0Mnej",
        "colab_type": "code",
        "outputId": "403ee55c-3132-4af0-bfbe-ac9c2bf9c2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def map_key_to_primer(key_string):\n",
        "    sha_signature = \\\n",
        "        hashlib.sha256(key_string.encode()).hexdigest()\n",
        "    sha_to_bin = str_to_bin(sha_signature)\n",
        "    bin_to_ternary = get_as_ternary(sha_to_bin)\n",
        "    n1 = bin_to_ternary[:(primer_len)]\n",
        "    n2 = bin_to_ternary[(-1*primer_len):]\n",
        "    primer1 = huffman_to_nucleotides(n1)\n",
        "    primer2 = huffman_to_nucleotides(n2)\n",
        "    return [primer1,primer2]\n",
        "\n",
        "print(map_key_to_primer('foo.txt'))\n",
        "print(map_key_to_primer('goo.txt'))\n",
        "print(map_key_to_primer('doo.txt'))\n",
        "print(map_key_to_primer('Firas'))\n",
        "print(map_key_to_primer('Muhammad'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['GTGACTGATC', 'GCGTAGTCTC']\n",
            "['GTACACTGAC', 'CTGTAGTCTA']\n",
            "['TAGTGCTAGT', 'TCATGAGTGT']\n",
            "['GAGTGTGACT', 'GCATGAGAGA']\n",
            "['GTACACTACT', 'TAGCATACAG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2vRjl0iTYNL",
        "colab_type": "text"
      },
      "source": [
        "# Data keys to High Bits of Address\n",
        "similarly to the previous section this part will take the data/file keys and translates them to nucleotides using different hash function and the same huffman to nucleotides translation that we used before. \n",
        "After this process is done those nucleotides which are the high bits of the fragements' addresses will be appended to the lower bits (will be explained in the next section) and together appended to the rest of the data and primers nucleotides.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QDB0WkCTg6q",
        "colab_type": "code",
        "outputId": "a6d8b12d-870d-412d-cd43-f55b6aa4167d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "def rand_indices(string: str):\n",
        "    ## Create a random generator using a fixed seed\n",
        "    rand_gen = np.random.RandomState(0)\n",
        "    ## Generating a vector of indices\n",
        "    indices = np.arange(0, len(string), 1)\n",
        "    ## Shuffle the indices\n",
        "    rand_gen.shuffle(indices)\n",
        "    return indices\n",
        "\n",
        "\n",
        "def map_key_to_high_address(key_string):\n",
        "    key_to_bin = str_to_bin(key_string)\n",
        "    bin_to_ternary = get_as_ternary(key_to_bin)\n",
        "    indices=rand_indices(bin_to_ternary)[0:high_address_len]\n",
        "    address = huffman_to_nucleotides(sub_str_from_indices(bin_to_ternary,indices))\n",
        "    return address\n",
        "\n",
        "def map_index_to_low_address(index):\n",
        "    low_address_len_aux = low_address_len * 2\n",
        "    to_ternary = ternary(index).rjust(low_address_len_aux, '2')\n",
        "    address = huffman_to_nucleotides(to_ternary)[-low_address_len:]\n",
        "    return address\n",
        "\n",
        "def map_key_to_pool_address(dna_library, key_string):\n",
        "    return hash(key_string) % (len(dna_library))\n",
        "\n",
        "\n",
        "print(map_key_to_high_address('foo.txt'))\n",
        "print(map_key_to_high_address('fpo.txt'))\n",
        "print(map_key_to_high_address('foo.txt'))\n",
        "\n",
        "\n",
        "def map_strand_to_RDP_table(key , index):\n",
        "    high_address = map_key_to_high_address(key)\n",
        "    val_hex = hashlib.sha256(high_address.encode()).hexdigest()\n",
        "    \n",
        "    # Get integer value of digest from the hexdigest\n",
        "    val_int = int(val_hex, 16) \n",
        "    #print('%064x' % val_int)   \n",
        "    map_val = val_int + int(index/4) ## base + offset\n",
        "    return map_val\n",
        "\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "    print(map_strand_to_RDP_table('foo.txt' , i))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CTGTA\n",
            "GATGT\n",
            "CTGTA\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425625\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425625\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425625\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425625\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425626\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425626\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425626\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425626\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425627\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425627\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425627\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425627\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425628\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425628\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425628\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425628\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425629\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425629\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425629\n",
            "94798299524441165247921464256416679112784556086823442995666859768943701425629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ICNpHAlMtFa",
        "colab_type": "text"
      },
      "source": [
        "#Digital data to \"nucleotides data\"\n",
        "Using the translation tables and functions from the previous sections, this function converts the digital data of the input file to nucleotides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SFsGrdpMuGB",
        "colab_type": "code",
        "outputId": "089a86de-d765-4421-d715-6e7a5c73cf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def digital_to_nucleotides(binary: str):\n",
        "    nucleotides_res = \"\"\n",
        "    for i in np.arange(0, len(binary), 8):\n",
        "        tmp_result = int(binary[i:i + 8], 2)\n",
        "        nucleotides_res += (huffman_code(tmp_result))\n",
        "    return huffman_to_nucleotides(nucleotides_res)\n",
        "\n",
        "def nucleotides_to_digital(sequence: str):\n",
        "    return huffman_to_binary(nucleotides_to_huffman(sequence))   \n",
        "\n",
        "\n",
        "binary_test = '010100000110111101101100011110010110000100111011'\n",
        "print(digital_to_nucleotides(binary_test))\n",
        "#GCGAGTGAGTATCGATGCTCTAGAGCATGTGA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GCGAGTGAGTATCGATGCTCTAGAGCATGTGA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRqpDSBgSjH1",
        "colab_type": "text"
      },
      "source": [
        "#Encode into Fragments\n",
        "In this section the file is first read, and then encoded from binary code to nucleotides data, which will be splitted into fragments according to the data's length and the number of the nucleotides that represent the digital data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGqdUSHRSjx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_path = \"https://raw.githubusercontent.com/Muhammad-Dahamshi/DNA-Storage-System/master/examples/\"\n",
        "cat_key = 'cat.jpg'\n",
        "smiley_key = 'smiley.jpg'\n",
        "sydney_key = 'sydney.jpg'\n",
        "txt_file_key = 'ex.txt'\n",
        "shakespeare_key = 'wssnt10.txt'\n",
        "corbett_key =  'corbett.pdf'\n",
        "small_key =  'result2.png'\n",
        "\n",
        "cat_path = dir_path + cat_key\n",
        "smiley_path = dir_path + smiley_key\n",
        "sydney_path = dir_path + sydney_key\n",
        "txt_file_path = dir_path + txt_file_key\n",
        "shakespeare_path = dir_path + shakespeare_key\n",
        "#reading the binary file\n",
        "def get_file_stream(input_file):\n",
        "    open_file_string = urlopen(input_file).read()\n",
        "    return ''.join(format(n, 'b').zfill(8) for n in open_file_string)\n",
        "# converting the digital data and split it into fragments\n",
        "def encode_payload(input_file, frag_len=pay_load_len):\n",
        "    lst = []\n",
        "    current_str = ''\n",
        "    digital_val = ''\n",
        "    open_file = urlopen(input_file)\n",
        "    stream =  get_file_stream(input_file)\n",
        "    stream_to_nucleotides = digital_to_nucleotides(stream)\n",
        "    return split_into_fragments(stream_to_nucleotides,frag_len)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9718V2R1sU_",
        "colab_type": "text"
      },
      "source": [
        "#Assembling Sequences\n",
        "These functions are responsible to gather all the translated nucleotides and appended in the right order in order to put it in the DNA pool.\n",
        "The primers are placed at the start and the end of each strand (we assumed that each primer's length is fixed to 10 nucleotides)\n",
        "the data nucleotides or what we've called the payload is appended to the address ( both high and low bits ) and then all assembled in the\n",
        "right order forming a strand orginated in the following way:\n",
        "\n",
        "***|Start_primer(10nucs)|sense_nuc(1nuc)|payload(80nucs)|high_address(5nucs)|low_address(15nucs)|sense_nuc|End_Primer(10nucs)|***\n",
        "![alt text](https://raw.githubusercontent.com/Muhammad-Dahamshi/DNA-Storage-System/master/examples/result2.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3yluCc1tqX",
        "colab_type": "code",
        "outputId": "07775847-ccbc-4292-e8ba-c4c0a75bc0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def append_payload_to_address(sequences_list: List[str], high_address):\n",
        "    lst = []\n",
        "    for i in range(len(sequences_list)):\n",
        "        low_address = map_index_to_low_address(i)\n",
        "        lst.append(sequences_list[i] + high_address + low_address)\n",
        "    return lst\n",
        "\n",
        "def assemble(sequences_list: List[str], primer1, primer2, high_address):\n",
        "    address_append_map = append_payload_to_address(sequences_list, high_address)\n",
        "    def append_primers_and_sense(seq, sense_nucleotides='A'):\n",
        "        return primer1 + sense_nucleotides + seq + sense_nucleotides + primer2\n",
        "    assembled = list(map(append_primers_and_sense, address_append_map))\n",
        "    complement_attach = [[strand,get_complement_seq(strand)] for strand in assembled]\n",
        "    return complement_attach\n",
        "\n",
        "def encode(key,rdp_library={},with_replication = False):\n",
        "    full_path = dir_path + key\n",
        "    primers = map_key_to_primer(key)\n",
        "    primer1 = primers[0]\n",
        "    primer2 = primers[1]\n",
        "    high_address = map_key_to_high_address(key)\n",
        "    encoded_payload = encode_payload(full_path)\n",
        "    \n",
        "    if with_replication:\n",
        "      x = len(encoded_payload)\n",
        "      to_save = (int(x/4)-1)*4 if (int(x/4)*4 == x) else (int(x/4))*4\n",
        "      for i in range(0,to_save,4):\n",
        "        table_i = RDP_table_from_strands(encoded_payload[i],encoded_payload[i+1],\n",
        "                              encoded_payload[i+2],encoded_payload[i+3])\n",
        "        index = map_strand_to_RDP_table(key,i)\n",
        "        rdp_library[str(index)] = table_i\n",
        "        #print_RDP_table(table_i)\n",
        "      #print(len(rdp_library))\n",
        "    assemble_sequences = assemble(encoded_payload, primer1, primer2, high_address)\n",
        "    return assemble_sequences\n",
        "\n",
        "# keys_list = [cat_key,smiley_key,sydney_key,txt_file_key,shakespeare_key]\n",
        "\n",
        "#print_colored(encode(smiley_key))\n",
        "#print(len(encode(cat_key)))\n",
        "#print(len(encode(smiley_key)))\n",
        "#print(len(encode(sydney_key)))\n",
        "#print(len(encode(txt_file_key)))\n",
        "#print(len(encode(shakespeare_key)))\n",
        "#print(len(encode(corbett_key)))\n",
        "print(len(encode(small_key))) #483\n",
        "\n",
        "x = len(encode(small_key))\n",
        "to_save = (int(x/4)-1)*4 if (int(x/4)*4 == x) else (int(x/4))*4\n",
        "print(to_save)\n",
        "#print_colored(encode(small_key))\n",
        "#print_colored(encode(txt_file_key))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "483\n",
            "480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHfEzq-S4jGU",
        "colab_type": "text"
      },
      "source": [
        "Smiley.png result\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/Muhammad-Dahamshi/DNA-Storage-System/master/examples/result1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EO5rwGA5rXy",
        "colab_type": "text"
      },
      "source": [
        "#Functions used in different sections:\n",
        "###Insert:\n",
        " after inserting the \"half DNA\" to the pool we append its complementary nucleotides for each strand so it will be a full DNA strand.\n",
        "###get_payload:\n",
        "This function extracts the payload nucleotides (data) from the full DNA strand in order to decode it and convert it back to binary code.\n",
        "###Search:\n",
        "uses the primers that it receives in order to find the needed strands from the right pool.\n",
        "###Create_DNA_Library:\n",
        "creates a group of pools that will be used to save data in. The right pool will be chosen using hash functions on the high bits of each file's address."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEtPkvmZ6CyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def insert(pool, strand_complement_pair):\n",
        "    pool.append(strand_complement_pair)\n",
        "\n",
        "def get_payload(strand: str):\n",
        "    nuc_to_cut_start = primer_len+1\n",
        "    nuc_to_cut_end = primer_len+low_address_len+high_address_len+1\n",
        "    payload = strand[nuc_to_cut_start:len(strand)-nuc_to_cut_end]\n",
        "    return payload\n",
        "\n",
        "def search(pool, primer1, primer2, length=primer_len):\n",
        "    lst = []\n",
        "    for strand_complement_pair in pool:\n",
        "        strand = strand_complement_pair[0]\n",
        "        if (strand[0:length] == primer1) \\\n",
        "                & (strand[-length:] == primer2):\n",
        "            lst.append(strand)\n",
        "    return lst\n",
        "\n",
        "def create_dna_library(size=dna_library_size):\n",
        "    lst = []\n",
        "    for i in range(size):\n",
        "        lst.append([])\n",
        "    return lst\n",
        "\n",
        "def RDP_library(size=dna_library_size):\n",
        "    dict = {}\n",
        "    for i in range(size):\n",
        "        lst.append([])\n",
        "    return lst\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9BO6Rd6-pl6",
        "colab_type": "text"
      },
      "source": [
        "# Row-Diagonal Parity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o01w9E7gtqZl",
        "colab_type": "text"
      },
      "source": [
        "### Row-Diagonal Parity auxiliary & utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neSJ0nebtqvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "nucleotides_dict = [ 'A' , 'C' , 'G' , 'T' ]\n",
        "\n",
        "nuc_to_num = lambda x : nucleotides_dict.index(x)\n",
        "num_to_nuc = lambda index : nucleotides_dict[index]\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "diag_full_length = [5 , 5, 5, 5, 4]\n",
        "\n",
        "def RDP_split(strand):\n",
        "      return split_into_fragments(strand,int(len(strand)/4))\n",
        "\n",
        "def create_RDP_table(p=5):\n",
        "    lst = []\n",
        "    for i in range(p-1):\n",
        "      row = []\n",
        "      for j in range(p+1):\n",
        "        row.append([])\n",
        "      lst.append(row)  \n",
        "    return lst\n",
        "\n",
        "def print_RDP_table(table , print_title = True):\n",
        "    data_num = len(table[0]) - 2 \n",
        "    block_len = max(25,len(table[0][0][0])) if len(table[0][0])> 0 else 25\n",
        "    if print_title:\n",
        "      titles = [\"data disk \"+str(i) for i in range(data_num)]\n",
        "      titles.extend([\"Row Parity\" , \"Diagonal Parity\"])\n",
        "      for title in titles:\n",
        "        print('{:^{len}}'.format(title,len=block_len),end = '')   \n",
        "      print('')  \n",
        "    for row in table:\n",
        "        for elem in row:\n",
        "          print('{:^{len}}'.format(str(elem),len=block_len),end = '')\n",
        "        print('')  \n",
        "\n",
        "def print_RDP_library(rdp_library):\n",
        "    for k, v in rdp_library.items():\n",
        "      print_aux('\\n{:^{len}}\\n'.format('{}'.format(k),len=120),'blue')\n",
        "      print_RDP_table(v)  \n",
        "\n",
        "def get_RDP_library_disks_state(rdp_library):\n",
        "    all_disks = 0\n",
        "    invalid_disks = 0\n",
        "    for k, v in rdp_library.items():\n",
        "      all_disks += 4\n",
        "      invalid_disks += len(get_table_missed_disks(v))\n",
        "    return invalid_disks,all_disks   \n",
        "\n",
        "def print_rdp_library_state(rdp_library):\n",
        "    invalid_disks,all_disks = get_RDP_library_disks_state(rdp_library)\n",
        "    print('{}{}'.format('All disks\\t',all_disks))\n",
        "    valid_percentage = int((all_disks-invalid_disks)/all_disks * 100)\n",
        "    print('{}{} ({}%)'.format('Valid disks :\\t',all_disks-invalid_disks,valid_percentage))\n",
        "    if(invalid_disks == 0):\n",
        "      print_aux('All data is valid\\n\\n','blue')\n",
        "    if(invalid_disks != 0):\n",
        "      answer = input(\"print failed desks info? enter yes or no\\n\")\n",
        "      if answer == \"yes\":\n",
        "          for k, v in rdp_library.items():\n",
        "            missed = get_table_missed_disks(v)\n",
        "            if missed != [] :\n",
        "              print_aux('disk uuid: {}\\t{}\\n'.format(k,'failed Desks {}'.format(missed)),'blue')\n",
        "      else:\n",
        "          return\n",
        "\n",
        "def get_table_missed_disks(table):\n",
        "    lst = []\n",
        "    data_num = len(table[0]) - 2\n",
        "    \n",
        "    for j in range(data_num+2):\n",
        "      for i in range(data_num):\n",
        "        if table[i][j] == ['ERROR']:\n",
        "          lst.append(j)\n",
        "          break\n",
        "    return lst\n",
        "\n",
        "def is_valid(table):\n",
        "    data_num = len(table[0]) - 2\n",
        "    for i in range(data_num):\n",
        "      for j in range(data_num+2):\n",
        "        if table[i][j] == ['ERROR']:\n",
        "          return False\n",
        "    return True      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tH9_tKuCZ2",
        "colab_type": "text"
      },
      "source": [
        "Row-Diagonal Parity data reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFsU6gMp-p7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def diag_row_distribution(data_num):\n",
        "    indexes = []\n",
        "    base = list(range(data_num+1))\n",
        "    for i in range(data_num):\n",
        "      diag = rotate(base,i)\n",
        "      diag.append(i)\n",
        "      indexes.append(diag)\n",
        "    return indexes  \n",
        "\n",
        "def diag_indexes(data_num,diag, with_diag_parity = True):\n",
        "    lst = []\n",
        "    indexes = diag_row_distribution(data_num)\n",
        "    last = data_num+2 if with_diag_parity else data_num+1\n",
        "    for col in range(last):\n",
        "      for row in range(data_num):\n",
        "        if indexes[row][col]==diag:\n",
        "          lst.append([col,row])\n",
        "    return lst  \n",
        "\n",
        "\n",
        "def table_get_diag(table , diag  , with_diag_parity = True):\n",
        "      diag_lst = []\n",
        "      data_num = len(table[0]) - 2\n",
        "      indexes = diag_indexes(data_num,diag,with_diag_parity)\n",
        "      for pair in indexes:\n",
        "        col = pair [0]\n",
        "        row = pair [1]\n",
        "        if table[row][col] != ['ERROR']: \n",
        "          diag_lst.append(table[row][col])\n",
        "      return diag_lst \n",
        "\n",
        "\n",
        "def nucleotides_XOR(*nucleotides):\n",
        "    def XOR_2(nuc1,nuc2):\n",
        "        assert len(nuc1) == len(nuc2)\n",
        "        nucs_len = len(nuc1)\n",
        "        #print(nuc1,nuc2, sep =' ')\n",
        "        return ''.join(num_to_nuc(nuc_to_num(nuc1[i])^nuc_to_num(nuc2[i])) for i in range(nucs_len))\n",
        "    nuc_len = len(nucleotides[0])\n",
        "    xor_res = \"A\" * nuc_len\n",
        "    for nuc in nucleotides: \n",
        "        xor_res = XOR_2(xor_res,nuc)\n",
        "    return xor_res\n",
        "\n",
        "def table_calc_diag_parity(table , diag):\n",
        "    diag_lst = table_get_diag(table , diag)\n",
        "    return nucleotides_XOR(*(flatten(diag_lst)))\n",
        "\n",
        "def table_calc_row_parity(table , row):\n",
        "    data_num = len(table[0]) - 2\n",
        "    return nucleotides_XOR(*(flatten(table[row][0:data_num])))\n",
        "\n",
        "def row_parity_fill(table):\n",
        "    data_num = len(table[0]) - 2\n",
        "    for row in range(data_num):\n",
        "        table[:][row][data_num].insert(0,table_calc_row_parity(table,row))     \n",
        "\n",
        "def diag_parity_fill(table):\n",
        "    data_num = len(table[0]) - 2\n",
        "    for diag in range(data_num): # the diagonal for which we do not store parity is the last (diag = 4)\n",
        "        table[:][diag][data_num + 1].insert(0,table_calc_diag_parity(table,diag))\n",
        "\n",
        "def down_disk(table,disk_index):\n",
        "    data_num = len(table[0]) - 2\n",
        "    for i in range(data_num):\n",
        "      table[:][i][disk_index] = ['ERROR']\n",
        "              \n",
        "\n",
        "def RDP_table_from_strands(*strands): #each strand is in a column (4 strands)\n",
        "    lst = []\n",
        "    for strand in strands:\n",
        "      lst.append(RDP_split(strand))\n",
        "    #print(lst)\n",
        "    table = create_RDP_table()\n",
        "    data_num = len(table[0]) - 2\n",
        "    for i in range(data_num):\n",
        "      for j in range(data_num):\n",
        "        table[i][j].insert(0,lst[j][i])\n",
        "    row_parity_fill(table)\n",
        "    diag_parity_fill(table)\n",
        "    return table  \n",
        "\n",
        "def RDP_table_from_strands(*strands): #each strand is in a column (4 strands)\n",
        "    lst = []\n",
        "    for strand in strands:\n",
        "      lst.append(RDP_split(strand))\n",
        "    #print(lst)\n",
        "    table = create_RDP_table()\n",
        "    data_num = len(table[0]) - 2\n",
        "    for i in range(data_num):\n",
        "      for j in range(data_num):\n",
        "        table[i][j].insert(0,lst[j][i])\n",
        "    row_parity_fill(table)\n",
        "    diag_parity_fill(table)\n",
        "    return table\n",
        "\n",
        "\n",
        "def RDP_recover_block_based_in_diag(table,diag,block_indexes_pair):\n",
        "    # A ^ B ^ C ^ D = E\n",
        "    # A missed -> new_A = E ^ B ^ C ^ D = (A ^ B ^ C ^ D)^ B ^ C ^ D \n",
        "    # E missed -> new_E = A ^ B ^ C ^ D = (A ^ B ^ C ^ D) \n",
        "    col = block_indexes_pair[1]\n",
        "    row = block_indexes_pair[0]\n",
        "    data_num = len(table[0]) - 2\n",
        "    \n",
        "    nucleotides = flatten(table_get_diag(table,diag))\n",
        "    diag_xor_calc = nucleotides_XOR(*(nucleotides))\n",
        "    new_block_data = diag_xor_calc\n",
        "    \n",
        "    if(len(table[row][col]) > 0): # remove invalid data (refresh)\n",
        "        table[:][row][col].pop()\n",
        "    table[:][row][col].insert(0,new_block_data)\n",
        "\n",
        "def RDP_recover_block_based_in_row(table,block_indexes_pair):\n",
        "    # A ^ B ^ C ^ D = E\n",
        "    # A missed -> new_A = E ^ B ^ C ^ D = (A ^ B ^ C ^ D)^ B ^ C ^ D \n",
        "    # E missed -> new_E = A ^ B ^ C ^ D = (A ^ B ^ C ^ D) \n",
        "    col = block_indexes_pair[1]\n",
        "    row = block_indexes_pair[0]\n",
        "    data_num = len(table[0]) - 2\n",
        "\n",
        "    valid_nucleotides = [] \n",
        "    for j in range(data_num+1):\n",
        "        if table[row][j] != ['ERROR']: \n",
        "          valid_nucleotides.append(table[row][j])\n",
        "          \n",
        "    row_xor_calc = nucleotides_XOR(*(flatten(valid_nucleotides)))\n",
        "    new_block_data = row_xor_calc\n",
        "    if(len(table[row][col]) > 0): # remove invalid data (refresh)\n",
        "        table[:][row][col].pop()\n",
        "    table[:][row][col].insert(0,new_block_data)\n",
        "\n",
        "def RDP_recover_completion(table,row):\n",
        "    # A ^ B ^ C ^ D = E\n",
        "    # A missed -> new_A = E ^ B ^ C ^ D = (A ^ B ^ C ^ D)^ B ^ C ^ D \n",
        "    # E missed -> new_E = A ^ B ^ C ^ D = (A ^ B ^ C ^ D) \n",
        "\n",
        "    data_num = len(table[0]) - 2\n",
        "    valid_nucleotides = [] \n",
        "    for j in range(data_num+1):\n",
        "        if table[row][j] != ['ERROR']:\n",
        "          valid_nucleotides.append(table[row][j])\n",
        "    if(len(valid_nucleotides) < data_num):\n",
        "      raise         \n",
        "    row_xor_calc = nucleotides_XOR(*(flatten(valid_nucleotides)))\n",
        "    new_block_data = row_xor_calc\n",
        "    for j in range(data_num+1):\n",
        "        if table[row][j] == ['ERROR']:\n",
        "            #print(\"old [{},{}]\".format(row,j),table[row][j])\n",
        "            table[:][row][j].pop() # remove invalid data (refresh)\n",
        "            table[:][row][j].insert(0,new_block_data) \n",
        "            #print(\"new [{},{}]\".format(row,j),table[row][j])\n",
        "\n",
        "def RDP_recover_disk(table,disk_index):\n",
        "    # A ^ B ^ C ^ D = E\n",
        "    # A missed -> new_A = E ^ B ^ C ^ D = (A ^ B ^ C ^ D)^ B ^ C ^ D \n",
        "    # E missed -> new_E = A ^ B ^ C ^ D = (A ^ B ^ C ^ D) \n",
        "    # diag recover\n",
        "    #disk_index =\n",
        "    data_num = len(table[0]) - 2 \n",
        "    indexes = diag_row_distribution(data_num)\n",
        "    \n",
        "    for diag in range(data_num): # list subtraction operation\n",
        "      valid_data = table_get_diag(table,diag)\n",
        "      full_diag = diag_full_length[diag]\n",
        "      if(len(valid_data) == full_diag-1): # we can recover this diag\n",
        "        for row in range(data_num):\n",
        "          if((indexes[row][disk_index] == diag) & (table[row][disk_index] == ['ERROR'])):\n",
        "            RDP_recover_block_based_in_diag(table,diag,[row,disk_index])\n",
        "            RDP_recover_completion(table,row)\n",
        "    return table\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFNGRz9KuUfT",
        "colab_type": "text"
      },
      "source": [
        "# Row-Diagonal Parity recover algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNlsJG9XuUs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RDP_recover(table): #each strand is in a column (4 strands)\n",
        "    lst = []\n",
        "    data_num = len(table[0]) - 2\n",
        "    missed_disks = get_table_missed_disks(table)\n",
        "    if (len(missed_disks) >= 3):\n",
        "      print('-'*150)  \n",
        "      print('{:^{len}}'.format('CURRENT TABLE IS NOT RECOVERABLE',len=120))   \n",
        "      print('-'*150)\n",
        "      raise\n",
        "    if (len(missed_disks) <= 0):\n",
        "      return table\n",
        "    recovred_table = table\n",
        "    while(is_valid(recovred_table) != True):\n",
        "      if(len(missed_disks) == 1):\n",
        "        for row in range(data_num):\n",
        "          disk = missed_disks[0]\n",
        "          RDP_recover_block_based_in_row(recovred_table,[row,disk])\n",
        "        return recovred_table \n",
        "      for disk in missed_disks:\n",
        "        recovred_table = RDP_recover_disk(recovred_table,disk)\n",
        "        missed_disks = get_table_missed_disks(recovred_table)\n",
        "        if (len(missed_disks) <= 0):\n",
        "          return recovred_table       \n",
        "    return None # we shouldn't get here\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCOPdxqmvChT",
        "colab_type": "text"
      },
      "source": [
        "# Row-Diagonal Parity TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jNDO9gvC11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def utility_rand_fill():\n",
        "    def rand_strand(length: int):\n",
        "        ## Create a random generator using a fixed seed\n",
        "        rand_gen = np.random.RandomState(0)\n",
        "        ## Generating a list of random strand\n",
        "        rand_strand = ''.join(random.choices(nucleotides_dict, k = length))\n",
        "        #print(rand_strand)\n",
        "        return rand_strand\n",
        "    table = create_RDP_table()\n",
        "    data_num = len(table[0]) - 2\n",
        "    for i in range(data_num):\n",
        "      for j in range(data_num):\n",
        "          table[i][j].insert(0,rand_strand(20))\n",
        "    return table\n",
        "\n",
        "# TAGTATATCGACTAGTACAG\n",
        "# AAAAAAAAAAAAAAAAAAAA\n",
        "# CGCGCGCGCGCGCGCGCGCG\n",
        "# CGCGCGCGCGCGCGCGCGCG\n",
        "# TTTTTTTTTTTTTTTTTTTT\n",
        "# RDP_table_from_strands('TAGTATATCGACTAGTACAG', 'CGTAGCATCTCGCAGCGAGA', 'TACGCTGCTACGCAGCATGC', 'TGTGAGTATCGATGACGAGT')\n",
        "\n",
        "def unit_text_nuc_xor():\n",
        "  print(nucleotides_XOR('A','C'))\n",
        "  print(nucleotides_XOR('AAA','ACG'))\n",
        "  print(nucleotides_XOR('C','G'))\n",
        "\n",
        "def unit_test_simple():\n",
        "    table = RDP_table_from_strands('AAAA', 'CGCG',\n",
        "                               'CGCG', 'TTTT')\n",
        "    print_RDP_table(table)\n",
        "    print(\"diag 0: \",table_get_diag(table,0))   \n",
        "    print(\"diag 1: \",table_get_diag(table,1))   \n",
        "    print(\"diag 2: \",table_get_diag(table,2))   \n",
        "    print(\"diag 3: \",table_get_diag(table,3))   \n",
        "    print(\"diag 4: \",table_get_diag(table,4))\n",
        "    data_num = len(table[0]) - 2\n",
        "    print(\"\\ndiag_row_indexes:\\n\",'\\n'.join(str(a) for a in diag_row_distribution(data_num)),sep='')\n",
        "  \n",
        "def unit_test_layout_and_data():\n",
        "    table = utility_rand_fill()\n",
        "    print_RDP_table(table)\n",
        "\n",
        "def unit_test_row_parity():\n",
        "    table = utility_rand_fill()\n",
        "    data_num = len(table[0]) - 2\n",
        "    row_parity_fill(table)\n",
        "    print_RDP_table(table)\n",
        "    for row in range(data_num):\n",
        "        row_parity = table[row][data_num][0]\n",
        "        nucleotides = flatten(table[row][0:data_num])\n",
        "        row_xor_calc = nucleotides_XOR(*(nucleotides))\n",
        "        print_aux('SUCCESS\\t','green') if row_parity == row_xor_calc \\\n",
        "        else print_aux('FAILED\\t','red')\n",
        "        print (\" {} ==== {}{}\\t\".format(row_parity,nucleotides[0],\n",
        "        ''.join(' ^ '+nuc for nuc in nucleotides[1:])))\n",
        "        assert row_parity == row_xor_calc\n",
        "\n",
        "def unit_test_diag_parity():\n",
        "    table = utility_rand_fill()\n",
        "    data_num = len(table[0]) - 2\n",
        "    row_parity_fill(table)\n",
        "    diag_parity_fill(table)\n",
        "    print_RDP_table(table)   \n",
        "    for diag in range(data_num): \n",
        "        diag_parity = table[diag][data_num+1][0]\n",
        "        nucleotides = flatten(table_get_diag(table,diag,with_diag_parity=False))\n",
        "        diag_xor_calc = nucleotides_XOR(*(nucleotides))\n",
        "        print_aux('SUCCESS\\t','green') if diag_parity == diag_xor_calc \\\n",
        "        else print_aux('FAILED\\t','red')\n",
        "        print (\" {} ==== {}{}\\t\".format(diag_parity,nucleotides[0],\n",
        "        ''.join(' ^ '+nuc for nuc in nucleotides[1:])))\n",
        "        assert diag_parity == diag_xor_calc\n",
        "\n",
        "def unit_test_RDP_table():\n",
        "    table = RDP_table_from_strands('TAGTATATCGACTAGTACAG', 'CGTAGCATCTCGCAGCGAGA', \n",
        "                           'TACGCTGCTACGCAGCATGC', 'TGTGAGTATCGATGACGAGT')\n",
        "    data_num = len(table[0]) - 2\n",
        "    print_RDP_table(table)\n",
        "\n",
        "    for i in range(data_num):\n",
        "        row_parity = table[i][data_num][0]\n",
        "        nucleotides = flatten(table[i][0:data_num])\n",
        "        row_xor_calc = nucleotides_XOR(*(nucleotides))\n",
        "        \n",
        "        diag_parity = table[i][data_num+1][0]\n",
        "        nucleotides = flatten(table_get_diag(table,i,with_diag_parity=False))\n",
        "        diag_xor_calc = nucleotides_XOR(*(nucleotides))\n",
        "        \n",
        "        print_aux('SUCCESS\\t','green') if row_parity == row_xor_calc \\\n",
        "        else print_aux('FAILED\\t','red')\n",
        "        print (\" {} ==== {}{}\\t\".format(row_parity,nucleotides[0],\n",
        "        ''.join(' ^ '+nuc for nuc in nucleotides[1:])))\n",
        "        assert row_parity == row_xor_calc\n",
        "\n",
        "        print_aux('SUCCESS\\t','green') if diag_parity == diag_xor_calc \\\n",
        "        else print_aux('FAILED\\t','red')\n",
        "        print (\" {} ==== {}{}\\t\".format(diag_parity,nucleotides[0],\n",
        "        ''.join(' ^ '+nuc for nuc in nucleotides[1:])))\n",
        "        assert diag_parity == diag_xor_calc\n",
        "\n",
        "\n",
        "def unit_test_single_block_recover():\n",
        "      print('-'*150)  \n",
        "      table = utility_rand_fill()\n",
        "      row_parity_fill(table)\n",
        "      diag_parity_fill(table)\n",
        "      print_RDP_table(table)\n",
        "      valid = table[1][2]\n",
        "\n",
        "      print_aux('\\n{:^{len}}\\n'.format('Diagonal parity reocover',len=120),'blue')\n",
        "\n",
        "      table[1][2] = ['ERROR']\n",
        "      print_RDP_table(table)\n",
        "      RDP_recover_block_based_in_diag(table,diag = 3,block_indexes_pair=[1,2])\n",
        "      print_RDP_table(table)\n",
        "      print_aux('\\n{:^{len}}\\n'.format('SUCCESS',len=120),'green') if table[1][2] == valid \\\n",
        "        else print_aux('\\n{:^{len}\\n}'.format('FAILED',len=120),'red')\n",
        "\n",
        "      print_aux('\\n{:^{len}}\\n'.format('Row parity reocover',len=120),'blue')\n",
        "      table[1][2] = ['ERROR']\n",
        "      print_RDP_table(table)\n",
        "      RDP_recover_block_based_in_row(table,block_indexes_pair=[1,2])\n",
        "      print_RDP_table(table) \n",
        "      print_aux('\\n{:^{len}}\\n'.format('SUCCESS',len=120),'green') if table[1][2] == valid \\\n",
        "        else print_aux('\\n{:^{len}\\n}'.format('FAILED',len=120),'red')\n",
        "       \n",
        "      print('-'*150)\n",
        "\n",
        "def unit_test_single_desk_recover(disk_index = 1):\n",
        "      print('-'*150)  \n",
        "      table = utility_rand_fill()\n",
        "      row_parity_fill(table)\n",
        "      diag_parity_fill(table)\n",
        "      down_disk(table,disk_index)\n",
        "      print_aux('\\n{:^{len}}\\n'.format('Single Desk reocover',len=120),'blue')\n",
        "      print_RDP_table(table)\n",
        "      recovred = RDP_recover_disk(table,disk_index)\n",
        "      print_RDP_table(recovred)\n",
        "      print('-'*150)\n",
        "\n",
        "def unit_test_two_desk_recover():\n",
        "    def disks_list(): \n",
        "          sublist = [] \n",
        "          for i in range(4):  \n",
        "              for j in range(i + 1, 4 , 1):\n",
        "                  sub = [i,j] \n",
        "                  sublist.append(sub)  \n",
        "          return sublist\n",
        "    def test_aux(missed):       \n",
        "          print('-'*150)\n",
        "          print_aux('\\n{:^{len}}\\n'.format('Two Desks {} reocover'.format(missed),len=120),'blue')  \n",
        "          table = RDP_table_from_strands('TCATGCACGTACATCTCGATCATAGCATGTACATCATGCACACTACTACAGTCGCGTATGCAGTGTCAGACAGACTGCGT'\n",
        ",'ATACTGATAGCTGTGCATGTCTCGAGAGCAGCATCACACGCAGCGTCGTGTACAGCACGCTGCTGTGTATGCGCGTATCA'\n",
        ",'TCTGCGCATGCGTCAGTGAGATCATGCGTGACGCTACGACTGATCTAGCTCGATCTAGCTCGATCTAGCTCGATCTAGCT'\n",
        ",'CGATCTAGCTCGATCTAGCTCGATCTAGCTCGATCTAGCTCGATGCATAGAGCGCATGCACATGCAGATCGTACGTGTAC')    \n",
        "\n",
        "          row_parity_fill(table)\n",
        "          diag_parity_fill(table)\n",
        "          print_RDP_table(table)\n",
        "          for i in missed:\n",
        "            down_disk(table,i)\n",
        "          print_RDP_table(table)\n",
        "          recovred = RDP_recover(table)\n",
        "          print_RDP_table(recovred)\n",
        "          print('-'*150)\n",
        "     \n",
        "    for m in disks_list():\n",
        "       test_aux(m) \n",
        "\n",
        "def run_test(test):\n",
        "    print('-'*150)  \n",
        "    print('{:^{len}}'.format(test.__name__,len=120))   \n",
        "    print('-'*150)\n",
        "    test()\n",
        "\n",
        "#run_test(unit_test_simple)\n",
        "#run_test(unit_test_layout_and_data)\n",
        "#run_test(unit_test_row_parity)\n",
        "#run_test(unit_test_diag_parity)\n",
        "#run_test(unit_test_RDP_table)\n",
        "#run_test(unit_test_single_block_recover)\n",
        "#run_test(unit_test_single_desk_recover)\n",
        "#run_test(unit_test_two_desk_recover)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZRoYLpYBc2p",
        "colab_type": "text"
      },
      "source": [
        "# PUT & GET\n",
        "In a nutshell, those are the processes of read and write.\n",
        "###Put:\n",
        "This function receives all the DNA pools and the a key, using the key it will put the right strands (including the complementary nucleotides, meaning a full DNA strand) in the right pool.\n",
        "###Get:\n",
        "This function extracts the needed file from the pool and converts the nucleotides back to binary code using the methods that are mentioned in previous sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdEggAIKBdQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put(key,dna_library, rdp_library = {} , with_replication = False):\n",
        "    value = encode(key,rdp_library,with_replication)\n",
        "    #print(len(rdp_library))\n",
        "    pool_address = map_key_to_pool_address(dna_library, key)\n",
        "    for strand_complement_pair in value:\n",
        "        insert(dna_library[pool_address],strand_complement_pair)\n",
        "\n",
        "\n",
        "def get(dna_library, key):\n",
        "    primers = map_key_to_primer(key)\n",
        "    primer1 = primers[0]\n",
        "    primer2 = primers[1]\n",
        "    pool_address = map_key_to_pool_address(dna_library, key)\n",
        "    res = search(dna_library[pool_address], primer1, primer2)\n",
        "    payloads = list(map(get_payload,search(dna_library[pool_address], primer1, primer2)))\n",
        "    return nucleotides_to_digital(''.join(payload for payload in payloads))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-U3D-bYAriB",
        "colab_type": "text"
      },
      "source": [
        "#Main - Testing\n",
        "Here we check our outcome on 5 different files (text files and images) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRfHi53_jy1e",
        "colab_type": "code",
        "outputId": "702c4b18-a0b0-4ef5-dea7-7fb125da0e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# function to generate all the sub lists \n",
        "def sub_lists(list1): \n",
        "    # store all the sublists  \n",
        "    sublist = [[]] \n",
        "    # first loop  \n",
        "    for i in range(len(list1) + 1):          \n",
        "        # second loop  \n",
        "        for j in range(i + 1, len(list1) + 1):              \n",
        "            # slice the subarray  \n",
        "            sub = list1[i:j] \n",
        "            sublist.append(sub)  \n",
        "    return sublist\n",
        "\n",
        "def check(keys):\n",
        "    if(len(keys)<=0):\n",
        "      return\n",
        "    # Declare a dictionary   \n",
        "    dna_library = create_dna_library()  \n",
        "    print(\"Testing #\" + str(len(keys)) + ' keys\\t:' + str(keys))\n",
        "    for key in keys:\n",
        "        put(key , dna_library)\n",
        "    for key in keys:\n",
        "        res1 = get_file_stream(dir_path+key)\n",
        "        res2 = get(dna_library, key)\n",
        "        print('\\'' + key + '\\'' + '\\t:', end='')\n",
        "        print_aux('SUCCESS\\n','green') if res1 == res2 else print_aux('FAILED\\n','red')\n",
        "    print('---------------------------------------------------------------------')   \n",
        "\n",
        "\n",
        "def check_recovery(key):\n",
        "    rdp_library = {}\n",
        "    dna_library = create_dna_library()\n",
        "    put(key , dna_library, rdp_library , with_replication = True)\n",
        "    valid_rdp = copy.deepcopy(rdp_library)\n",
        "    _,all_disks = get_RDP_library_disks_state(rdp_library)\n",
        "    # print_rdp_library_state(rdp_library)\n",
        "    # print(len(rdp_library))\n",
        "    for k, v in rdp_library.items():\n",
        "      num1 = random.randint(0, 3)\n",
        "      num2 = random.randint(0, 3)\n",
        "      down_disk(v,num1)\n",
        "      down_disk(v,num2)\n",
        "    print_rdp_library_state(rdp_library)\n",
        "    answer = input(\"\\n\\nprint all desks state? enter yes or no\\n\")\n",
        "    if answer == \"yes\":\n",
        "        print_RDP_library(rdp_library)\n",
        "    print_aux('{}\\n{:^{len}}\\n{}\\n'.format('*'*150,'data reocovering Start','*'*150,len=120), 'cyan')\n",
        "    bar = progressbar.ProgressBar(maxval=all_disks, \\\n",
        "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "    bar.start()\n",
        "    i = 1\n",
        "    for k, v in rdp_library.items():\n",
        "        i = i+1\n",
        "        RDP_recover(v)\n",
        "        bar.update(i)\n",
        "    bar.finish()\n",
        "    print_rdp_library_state(rdp_library)\n",
        "    invalid_disks,all_disks = get_RDP_library_disks_state(rdp_library)\n",
        "    print_aux('\\n{:^{len}}\\n'.format('check_recovery test result: SUCCESS\\t',len=120),'green') if rdp_library == valid_rdp \\\n",
        "        else print_aux('\\n{:^{len}}\\n'.format('check_recovery test result: FAILED\\t',len=120),'red')\n",
        "    answer = input(\"\\n\\nprint recovered desks state? enter yes or no\\n\")\n",
        "    if answer == \"yes\":\n",
        "        print_RDP_library(rdp_library)\n",
        "\n",
        "\n",
        "def main():\n",
        "    keys_list = [cat_key,smiley_key,sydney_key,txt_file_key,shakespeare_key,small_key]\n",
        "    keys_sub_lists = sub_lists(keys_list)\n",
        "    keys_sub_lists.sort(key=len)\n",
        "    #for sub_list in keys_sub_lists:\n",
        "    #  check(sub_list)\n",
        "    # check(keys_list)\n",
        "    check_recovery(small_key)\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All disks\t480\n",
            "Valid disks :\t270 (56%)\n",
            "print failed desks info? enter yes or no\n",
            "no\n",
            "\n",
            "\n",
            "print all desks state? enter yes or no\n",
            "no\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m******************************************************************************************************************************************************\n",
            "                                                 data reocovering Start                                                 \n",
            "******************************************************************************************************************************************************\n",
            "\u001b[0mAll disks\t480\n",
            "Valid disks :\t480 (100%)\n",
            "\u001b[34m\u001b[1mAll data is valid\n",
            "\n",
            "\u001b[0m\u001b[32m\u001b[1m\n",
            "                                          check_recovery test result: SUCCESS\t                                          \n",
            "\u001b[0m\n",
            "\n",
            "print recovered desks state? enter yes or no\n",
            "no\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
